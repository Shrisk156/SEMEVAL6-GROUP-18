{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "c8536a8c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8536a8c",
        "outputId": "f0739c64-8c01-4e52-f635-75fdf771164a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: datasets in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (4.4.1)\n",
            "Requirement already satisfied: httpx<1.0.0 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: fsspec[http]<=2025.10.0,>=2023.1.0 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (2025.10.0)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (0.36.0)\n",
            "Requirement already satisfied: requests>=2.32.2 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (2.32.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (21.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: filelock in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (3.19.1)\n",
            "Requirement already satisfied: pandas in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (2.3.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: multiprocess<0.70.19 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (0.70.18)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (5.0.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from aiosignal>=1.4.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: certifi in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
            "Requirement already satisfied: idna in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from httpx<1.0.0->datasets) (3.11)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: anyio in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
            "Requirement already satisfied: h11>=0.16 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.15.0)\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.3 is available.\n",
            "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "41f59211-a54d-4ed1-bec4-b8cad1ce4f08",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41f59211-a54d-4ed1-bec4-b8cad1ce4f08",
        "outputId": "52be70cf-f574-4bf0-a36a-b72a0e6d245c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4c0bb1ed",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c0bb1ed",
        "outputId": "72d73c3f-22ad-46de-ccd3-5d9470ba2ba3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# importing the dataset directly from huggingface\n",
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "# Login using e.g. `huggingface-cli login` to access this dataset\n",
        "ds = load_dataset(\"ailsntua/QEvasion\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e1b3e2ad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1b3e2ad",
        "outputId": "34e53a1c-2069-4f07-b5a2-5959290cbae6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['title', 'date', 'president', 'url', 'question_order', 'interview_question', 'interview_answer', 'gpt3.5_summary', 'gpt3.5_prediction', 'question', 'annotator_id', 'annotator1', 'annotator2', 'annotator3', 'inaudible', 'multiple_questions', 'affirmative_questions', 'index', 'clarity_label', 'evasion_label'],\n",
              "        num_rows: 3448\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['title', 'date', 'president', 'url', 'question_order', 'interview_question', 'interview_answer', 'gpt3.5_summary', 'gpt3.5_prediction', 'question', 'annotator_id', 'annotator1', 'annotator2', 'annotator3', 'inaudible', 'multiple_questions', 'affirmative_questions', 'index', 'clarity_label', 'evasion_label'],\n",
              "        num_rows: 308\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d143540b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d143540b",
        "outputId": "3ad30db8-995e-43b1-92af-0b3ad7edb1d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train sample:\n",
            " {'title': \"The President's News Conference in Hanoi, Vietnam\", 'date': 'September 10, 2023', 'president': 'Joseph R. Biden', 'url': 'https://www.presidency.ucsb.edu/documents/the-presidents-news-conference-hanoi-vietnam-0', 'question_order': 1, 'interview_question': 'Q. Of the Biden administration. And accused the United States of containing China while pushing for diplomatic talks.How would you respond to that? And do you think President Xi is being sincere about getting the relationship back on track as he bans Apple in China?', 'interview_answer': \"Well, look, first of all, theI am sincere about getting the relationship right. And one of the things that is going on now is, China is beginning to change some of the rules of the game, in terms of trade and other issues.And so one of the things we talked about, for example, is that they're now talking about making sure that no Chineseno one in the Chinese Government can use a Western cell phone. Those kinds of things.And so, really, what this trip was aboutit was less about containing China. I don't want to contain China. I just want to make sure that we have a relationship with China that is on the up and up, squared away, everybody knows what it's all about. And one of the ways you do that is, you make sure that we are talking about the same things.And I think that one of the things we've doneI've tried to do, and I've talked with a number of my staff about this for the last, I guess, 6 monthsis, we have an opportunity to strengthen alliances around the world to maintain stability.That's what this trip was all about: having India cooperate much more with the United States, be closer with the United States, Vietnam being closer with the United States. It's not about containing China; it's about having a stable base, a stable base in the Indo-Pacific.And it'sfor example, when I was spending a lot of time talking with President Xi, he asked why we were doingwhy was I going to have the Quad, meaning Australia, India, Japan, and the United States? And I said, To maintain stability. It's not about isolating China. It's about making sure the rules of the roadeverything from airspace and space in the ocean isthe international rules of the road are abided by.And soand I hope thatI think that Prime Minister XiI mean, Xi has somesome difficulties right now. All countries end up with difficulties, and he had some economic difficulties he's working his way through. I want to see China succeed economically, but I want to see them succeed by the rules.The next question was to Bloomberg.\", 'gpt3.5_summary': 'The question consists of 2 parts: \\n1. How would you respond to the accusation that the United States is containing China while pushing for diplomatic talks?\\n2. Do you think President Xi is being sincere about getting the relationship back on track as he bans Apple in China?\\n\\nThe response provides the following information regarding these points:\\n1. The President expresses sincerity about getting the relationship between the United States and China right.\\n2. China is changing some of the rules of the game, such as banning Chinese government officials from using Western cell phones.\\n3. The purpose of the trip was not to contain China but to establish a stable relationship with China and strengthen alliances in the Indo-Pacific region.\\n4. The Quad (Australia, India, Japan, and United States) is not meant to isolate China but to maintain stability and ensure that international rules are followed.\\n5. President Xi has some economic difficulties, and the President hopes to see China succeed economically while also following the rules.', 'gpt3.5_prediction': \"Question part: 1. How would you respond to the accusation that the United States is containing China while pushing for diplomatic talks?\\nVerdict: 1.1 Explicit - The information requested is explicitly stated (in the requested form)\\nExplanation: The President directly responds to the accusation by stating that the purpose of the trip and their approach is not about containing China but about establishing a stable relationship and ensuring that both countries are on the same page.\\n\\nQuestion part: 2. Do you think President Xi is being sincere about getting the relationship back on track as he bans Apple in China?\\nVerdict: 1.1 Explicit - The information requested is explicitly stated (in the requested form)\\nExplanation: The President explicitly expresses their belief in President Xi's sincerity about getting the relationship back on track while also mentioning the difficulties China is facing and their hope that China follows the rules.\", 'question': 'How would you respond to the accusation that the United States is containing China while pushing for diplomatic talks?', 'annotator_id': '85', 'annotator1': None, 'annotator2': None, 'annotator3': None, 'inaudible': False, 'multiple_questions': False, 'affirmative_questions': False, 'index': 0, 'clarity_label': 'Clear Reply', 'evasion_label': 'Explicit'}\n",
            "\n",
            "Columns:\n",
            " ['title', 'date', 'president', 'url', 'question_order', 'interview_question', 'interview_answer', 'gpt3.5_summary', 'gpt3.5_prediction', 'question', 'annotator_id', 'annotator1', 'annotator2', 'annotator3', 'inaudible', 'multiple_questions', 'affirmative_questions', 'index', 'clarity_label', 'evasion_label']\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nTrain sample:\\n\", ds[\"train\"][0])\n",
        "print(\"\\nColumns:\\n\", ds[\"train\"].column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "86a8daf7",
      "metadata": {
        "id": "86a8daf7"
      },
      "outputs": [],
      "source": [
        "MODEL = \"roberta-base\"\n",
        "MAX_LENGTH = 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b1d9f527",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1d9f527",
        "outputId": "bbc4e062-dda0-47f7-f489-0e681b510932"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (5.29.5)\n"
          ]
        }
      ],
      "source": [
        "pip install sentencepiece protobuf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "7cde6dc3-78fe-46d0-921f-d3a257c0b092",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cde6dc3-78fe-46d0-921f-d3a257c0b092",
        "outputId": "1646bf09-5b9e-473f-be1f-6962c5344e7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cu126)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "pip install transformers datasets scikit-learn accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b61f2045",
      "metadata": {
        "id": "b61f2045"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from datasets import load_dataset, DatasetDict\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.utils.class_weight import compute_class_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "21659d9f",
      "metadata": {
        "id": "21659d9f"
      },
      "outputs": [],
      "source": [
        "# pip install --upgrade transformers huggingface_hub accelerate sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "91e15a1d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91e15a1d",
        "outputId": "18b6a7e5-afea-4902-fe26-574e3a4e90dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset Columns: ['title', 'date', 'president', 'url', 'question_order', 'interview_question', 'interview_answer', 'gpt3.5_summary', 'gpt3.5_prediction', 'question', 'annotator_id', 'annotator1', 'annotator2', 'annotator3', 'inaudible', 'multiple_questions', 'affirmative_questions', 'index', 'clarity_label', 'evasion_label']\n",
            "Sample Entry: {'title': \"The President's News Conference in Hanoi, Vietnam\", 'date': 'September 10, 2023', 'president': 'Joseph R. Biden', 'url': 'https://www.presidency.ucsb.edu/documents/the-presidents-news-conference-hanoi-vietnam-0', 'question_order': 1, 'interview_question': 'Q. Of the Biden administration. And accused the United States of containing China while pushing for diplomatic talks.How would you respond to that? And do you think President Xi is being sincere about getting the relationship back on track as he bans Apple in China?', 'interview_answer': \"Well, look, first of all, theI am sincere about getting the relationship right. And one of the things that is going on now is, China is beginning to change some of the rules of the game, in terms of trade and other issues.And so one of the things we talked about, for example, is that they're now talking about making sure that no Chineseno one in the Chinese Government can use a Western cell phone. Those kinds of things.And so, really, what this trip was aboutit was less about containing China. I don't want to contain China. I just want to make sure that we have a relationship with China that is on the up and up, squared away, everybody knows what it's all about. And one of the ways you do that is, you make sure that we are talking about the same things.And I think that one of the things we've doneI've tried to do, and I've talked with a number of my staff about this for the last, I guess, 6 monthsis, we have an opportunity to strengthen alliances around the world to maintain stability.That's what this trip was all about: having India cooperate much more with the United States, be closer with the United States, Vietnam being closer with the United States. It's not about containing China; it's about having a stable base, a stable base in the Indo-Pacific.And it'sfor example, when I was spending a lot of time talking with President Xi, he asked why we were doingwhy was I going to have the Quad, meaning Australia, India, Japan, and the United States? And I said, To maintain stability. It's not about isolating China. It's about making sure the rules of the roadeverything from airspace and space in the ocean isthe international rules of the road are abided by.And soand I hope thatI think that Prime Minister XiI mean, Xi has somesome difficulties right now. All countries end up with difficulties, and he had some economic difficulties he's working his way through. I want to see China succeed economically, but I want to see them succeed by the rules.The next question was to Bloomberg.\", 'gpt3.5_summary': 'The question consists of 2 parts: \\n1. How would you respond to the accusation that the United States is containing China while pushing for diplomatic talks?\\n2. Do you think President Xi is being sincere about getting the relationship back on track as he bans Apple in China?\\n\\nThe response provides the following information regarding these points:\\n1. The President expresses sincerity about getting the relationship between the United States and China right.\\n2. China is changing some of the rules of the game, such as banning Chinese government officials from using Western cell phones.\\n3. The purpose of the trip was not to contain China but to establish a stable relationship with China and strengthen alliances in the Indo-Pacific region.\\n4. The Quad (Australia, India, Japan, and United States) is not meant to isolate China but to maintain stability and ensure that international rules are followed.\\n5. President Xi has some economic difficulties, and the President hopes to see China succeed economically while also following the rules.', 'gpt3.5_prediction': \"Question part: 1. How would you respond to the accusation that the United States is containing China while pushing for diplomatic talks?\\nVerdict: 1.1 Explicit - The information requested is explicitly stated (in the requested form)\\nExplanation: The President directly responds to the accusation by stating that the purpose of the trip and their approach is not about containing China but about establishing a stable relationship and ensuring that both countries are on the same page.\\n\\nQuestion part: 2. Do you think President Xi is being sincere about getting the relationship back on track as he bans Apple in China?\\nVerdict: 1.1 Explicit - The information requested is explicitly stated (in the requested form)\\nExplanation: The President explicitly expresses their belief in President Xi's sincerity about getting the relationship back on track while also mentioning the difficulties China is facing and their hope that China follows the rules.\", 'question': 'How would you respond to the accusation that the United States is containing China while pushing for diplomatic talks?', 'annotator_id': '85', 'annotator1': None, 'annotator2': None, 'annotator3': None, 'inaudible': False, 'multiple_questions': False, 'affirmative_questions': False, 'index': 0, 'clarity_label': 'Clear Reply', 'evasion_label': 'Explicit'}\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nDataset Columns:\", ds['train'].column_names)\n",
        "print(\"Sample Entry:\", ds['train'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b684b10f",
      "metadata": {
        "id": "b684b10f"
      },
      "outputs": [],
      "source": [
        "LABEL_NORMALIZER = {\n",
        "    # Clear Reply mappings\n",
        "    'explicit': 'Explicit',\n",
        "    'clear reply': 'Explicit',\n",
        "    'clear': 'Explicit',\n",
        "\n",
        "    # Ambivalent (Evasion) mappings\n",
        "    'implicit': 'Implicit',\n",
        "    'dodging': 'Dodging',\n",
        "    'general': 'General',\n",
        "    'deflection': 'Deflection',\n",
        "    'partial': 'Partial/half-answer',\n",
        "    'partial/half-answer': 'Partial/half-answer',\n",
        "\n",
        "    # Clear Non-Reply mappings\n",
        "    'declining': 'Declining to answer',\n",
        "    'declining to answer': 'Declining to answer',\n",
        "    'ignorance': 'Claims ignorance',\n",
        "    'claims ignorance': 'Claims ignorance',\n",
        "    'clarification': 'Clarification',\n",
        "\n",
        "    # Fallback mappings\n",
        "    'clear non-reply': 'Declining to answer',\n",
        "    'ambivalent': 'Implicit', # Default ambivalent to Implicit if unspecified\n",
        "    'ambiguous': 'Implicit'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6504df4a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6504df4a",
        "outputId": "b68a8f9b-842b-43bb-8d91-b85b1a8538d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing 3448 original rows...\n"
          ]
        }
      ],
      "source": [
        "raw_df = ds['train'].to_pandas()\n",
        "\n",
        "expanded_rows = []\n",
        "\n",
        "print(f\"Processing {len(raw_df)} original rows...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "2dfa31a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dfa31a0",
        "outputId": "0060c499-7b28-4fe9-edcd-2415c6282ef3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Training Size: 3448 (Exploded from 3448)\n",
            "Classes Found: ['Explicit' 'General' 'Partial/half-answer' 'Dodging' 'Implicit'\n",
            " 'Deflection' 'Declining to answer' 'Claims ignorance' 'Clarification']\n"
          ]
        }
      ],
      "source": [
        "for _, row in raw_df.iterrows():\n",
        "    q_text = row['interview_question']\n",
        "    a_text = row['interview_answer']\n",
        "\n",
        "    # Collect all potential labels for this row\n",
        "    potential_labels = []\n",
        "\n",
        "    # A. Check the 3 Annotators (Priority: High)\n",
        "    # The FAQ states any annotator is valid, so we train on ALL of them[cite: 210].\n",
        "    for col in ['annotator1', 'annotator2', 'annotator3']:\n",
        "        val = row.get(col)\n",
        "        if val and str(val).lower() not in ['nan', 'none', '']:\n",
        "            potential_labels.append(str(val).strip())\n",
        "\n",
        "    # B. If no annotators (Training set usually), use evasion_label\n",
        "    if not potential_labels:\n",
        "        val = row.get('evasion_label')\n",
        "        if val and str(val).lower() not in ['nan', 'none', '']:\n",
        "            potential_labels.append(str(val).strip())\n",
        "\n",
        "    # C. Fallback: Use clarity_label if evasion is missing\n",
        "    # (e.g., \"Clear Reply\" -> \"Explicit\")\n",
        "    if not potential_labels:\n",
        "        clarity = row.get('clarity_label')\n",
        "        if clarity == 'Clear Reply':\n",
        "            potential_labels.append('Explicit')\n",
        "        elif clarity == 'Clear Non-Reply':\n",
        "            potential_labels.append('Declining to answer') # Generic fallback\n",
        "\n",
        "    # Add normalized rows to training data\n",
        "    for raw_label in potential_labels:\n",
        "        # Normalize (e.g., \"Partial\" -> \"Partial/half-answer\")\n",
        "        clean_label = LABEL_NORMALIZER.get(raw_label, raw_label)\n",
        "\n",
        "        # Only add if it's one of our valid target classes\n",
        "        if clean_label in LABEL_NORMALIZER.values():\n",
        "            expanded_rows.append({\n",
        "                \"text\": q_text,\n",
        "                \"text_pair\": a_text,\n",
        "                \"label_str\": clean_label\n",
        "            })\n",
        "\n",
        "# Create final dataframe\n",
        "df_train = pd.DataFrame(expanded_rows)\n",
        "print(f\"Final Training Size: {len(df_train)} (Exploded from {len(raw_df)})\")\n",
        "print(f\"Classes Found: {df_train['label_str'].unique()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "41a292da",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41a292da",
        "outputId": "ed3c2a67-ec82-45b6-dce1-ed1896a3a9db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class Weights applied: tensor([3.2194, 4.1643, 2.6421, 1.0055, 0.5427, 0.3642, 0.9925, 0.7851, 4.8495],\n",
            "       device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "unique_labels = sorted(df_train['label_str'].unique().tolist())\n",
        "label2id = {l: i for i, l in enumerate(unique_labels)}\n",
        "id2label = {i: l for i, l in enumerate(unique_labels)}\n",
        "\n",
        "df_train['labels'] = df_train['label_str'].map(label2id)\n",
        "\n",
        "# Compute Weights to handle imbalance (Explicit is ~30%, Clarification ~2%) [cite: 991]\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(df_train['labels']),\n",
        "    y=df_train['labels']\n",
        ")\n",
        "weights_tensor = torch.tensor(class_weights, dtype=torch.float)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "weights_tensor = weights_tensor.to(device)\n",
        "\n",
        "print(f\"Class Weights applied: {weights_tensor}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "8c7219db",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "3a75c5a34ade473e82690aa02317e761",
            "20930689ae6d4072a7c8e8afc1176f59",
            "c9ae086fc4b643429382bfb7ec898b8b",
            "c746f461798246208f3e15cdcc8da7ec",
            "245069cb1b3f4d81b6a24ae5ea6dd446",
            "b152eec268b148dcaf33ecee54e36a95",
            "77a6ad771d9c41b1b04114899c16dd8f",
            "9892708732914ab5a572803f9630e54b",
            "0ba54f350e784f29980be61c02da4299",
            "14b5e22813ec4fde9730edb3510b7ed0",
            "19aad6cb65154503b26e8d06a7c8f414"
          ]
        },
        "id": "8c7219db",
        "outputId": "7de91b1e-154a-4526-eb6f-629b34d6da5e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a75c5a34ade473e82690aa02317e761",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/3448 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],\n",
        "        examples[\"text_pair\"],\n",
        "        truncation=True,\n",
        "        max_length=MAX_LENGTH,\n",
        "        padding=\"max_length\"\n",
        "    )\n",
        "\n",
        "hf_dataset = Dataset.from_pandas(df_train)\n",
        "hf_dataset = hf_dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# Prepare for PyTorch\n",
        "cols = ['input_ids', 'attention_mask', 'labels']\n",
        "if 'token_type_ids' in hf_dataset.column_names: cols.append('token_type_ids')\n",
        "hf_dataset.set_format(type='torch', columns=cols)\n",
        "\n",
        "# 90/10 Train/Validation Split\n",
        "split_ds = hf_dataset.train_test_split(test_size=0.1, seed=42)\n",
        "test_dataset = split_ds['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "22ac2b44",
      "metadata": {
        "id": "22ac2b44"
      },
      "outputs": [],
      "source": [
        "class WeightedTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "        # Weighted Cross Entropy to help rare classes\n",
        "        loss_fct = nn.CrossEntropyLoss(weight=weights_tensor)\n",
        "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    # Metric is Macro F1 as per shared task guidelines [cite: 1068]\n",
        "    return {\"f1_macro\": f1_score(labels, predictions, average='macro')}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "dfeeec7c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfeeec7c",
        "outputId": "e594b049-bd3f-4597-c7de-780b2f2eaedb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.12/dist-packages (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "pip install \"numpy<2.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "2c34d9e9",
      "metadata": {
        "id": "2c34d9e9"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "8e65dca9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "8e65dca9",
        "outputId": "62b8f847-b7b2-4d54-9ac1-ee8d5d01f2be"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-3815370037.py:22: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = WeightedTrainer(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting Training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1940' max='1940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1940/1940 27:03, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.967547</td>\n",
              "      <td>0.185123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.081900</td>\n",
              "      <td>1.792706</td>\n",
              "      <td>0.217615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.790300</td>\n",
              "      <td>1.794834</td>\n",
              "      <td>0.301735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.590900</td>\n",
              "      <td>1.814894</td>\n",
              "      <td>0.340802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.590900</td>\n",
              "      <td>1.838561</td>\n",
              "      <td>0.319709</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1940, training_loss=1.7208361124254994, metrics={'train_runtime': 1624.9738, 'train_samples_per_second': 9.548, 'train_steps_per_second': 1.194, 'total_flos': 4082424588887040.0, 'train_loss': 1.7208361124254994, 'epoch': 5.0})"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL,\n",
        "    num_labels=len(unique_labels),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ").to(device)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./clarity_final_model\",\n",
        "    learning_rate=2e-5,              # Recommended by paper [cite: 1162]\n",
        "    per_device_train_batch_size=8,   # Adjust to 4 if OOM\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=5,              # 5 epochs for convergence\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1_macro\",\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = WeightedTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=split_ds[\"train\"],\n",
        "    eval_dataset=split_ds[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "print(\"\\nStarting Training...\")\n",
        "trainer.train()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
