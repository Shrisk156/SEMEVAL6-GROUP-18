{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8536a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: datasets in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (4.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: httpx<1.0.0 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: fsspec[http]<=2025.10.0,>=2023.1.0 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (2025.10.0)\n",
      "Requirement already satisfied: packaging in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: pandas in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: filelock in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (3.19.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from aiosignal>=1.4.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: certifi in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: anyio in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.3 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c0bb1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saiesh/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/saiesh/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# importing the dataset directly from huggingface\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "ds = load_dataset(\"ailsntua/QEvasion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1b3e2ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'date', 'president', 'url', 'question_order', 'interview_question', 'interview_answer', 'gpt3.5_summary', 'gpt3.5_prediction', 'question', 'annotator_id', 'annotator1', 'annotator2', 'annotator3', 'inaudible', 'multiple_questions', 'affirmative_questions', 'index', 'clarity_label', 'evasion_label'],\n",
       "        num_rows: 3448\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['title', 'date', 'president', 'url', 'question_order', 'interview_question', 'interview_answer', 'gpt3.5_summary', 'gpt3.5_prediction', 'question', 'annotator_id', 'annotator1', 'annotator2', 'annotator3', 'inaudible', 'multiple_questions', 'affirmative_questions', 'index', 'clarity_label', 'evasion_label'],\n",
       "        num_rows: 308\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d143540b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train sample:\n",
      " {'title': \"The President's News Conference in Hanoi, Vietnam\", 'date': 'September 10, 2023', 'president': 'Joseph R. Biden', 'url': 'https://www.presidency.ucsb.edu/documents/the-presidents-news-conference-hanoi-vietnam-0', 'question_order': 1, 'interview_question': 'Q. Of the Biden administration. And accused the United States of containing China while pushing for diplomatic talks.How would you respond to that? And do you think President Xi is being sincere about getting the relationship back on track as he bans Apple in China?', 'interview_answer': \"Well, look, first of all, theI am sincere about getting the relationship right. And one of the things that is going on now is, China is beginning to change some of the rules of the game, in terms of trade and other issues.And so one of the things we talked about, for example, is that they're now talking about making sure that no Chineseno one in the Chinese Government can use a Western cell phone. Those kinds of things.And so, really, what this trip was aboutit was less about containing China. I don't want to contain China. I just want to make sure that we have a relationship with China that is on the up and up, squared away, everybody knows what it's all about. And one of the ways you do that is, you make sure that we are talking about the same things.And I think that one of the things we've doneI've tried to do, and I've talked with a number of my staff about this for the last, I guess, 6 monthsis, we have an opportunity to strengthen alliances around the world to maintain stability.That's what this trip was all about: having India cooperate much more with the United States, be closer with the United States, Vietnam being closer with the United States. It's not about containing China; it's about having a stable base, a stable base in the Indo-Pacific.And it'sfor example, when I was spending a lot of time talking with President Xi, he asked why we were doingwhy was I going to have the Quad, meaning Australia, India, Japan, and the United States? And I said, To maintain stability. It's not about isolating China. It's about making sure the rules of the roadeverything from airspace and space in the ocean isthe international rules of the road are abided by.And soand I hope thatI think that Prime Minister XiI mean, Xi has somesome difficulties right now. All countries end up with difficulties, and he had some economic difficulties he's working his way through. I want to see China succeed economically, but I want to see them succeed by the rules.The next question was to Bloomberg.\", 'gpt3.5_summary': 'The question consists of 2 parts: \\n1. How would you respond to the accusation that the United States is containing China while pushing for diplomatic talks?\\n2. Do you think President Xi is being sincere about getting the relationship back on track as he bans Apple in China?\\n\\nThe response provides the following information regarding these points:\\n1. The President expresses sincerity about getting the relationship between the United States and China right.\\n2. China is changing some of the rules of the game, such as banning Chinese government officials from using Western cell phones.\\n3. The purpose of the trip was not to contain China but to establish a stable relationship with China and strengthen alliances in the Indo-Pacific region.\\n4. The Quad (Australia, India, Japan, and United States) is not meant to isolate China but to maintain stability and ensure that international rules are followed.\\n5. President Xi has some economic difficulties, and the President hopes to see China succeed economically while also following the rules.', 'gpt3.5_prediction': \"Question part: 1. How would you respond to the accusation that the United States is containing China while pushing for diplomatic talks?\\nVerdict: 1.1 Explicit - The information requested is explicitly stated (in the requested form)\\nExplanation: The President directly responds to the accusation by stating that the purpose of the trip and their approach is not about containing China but about establishing a stable relationship and ensuring that both countries are on the same page.\\n\\nQuestion part: 2. Do you think President Xi is being sincere about getting the relationship back on track as he bans Apple in China?\\nVerdict: 1.1 Explicit - The information requested is explicitly stated (in the requested form)\\nExplanation: The President explicitly expresses their belief in President Xi's sincerity about getting the relationship back on track while also mentioning the difficulties China is facing and their hope that China follows the rules.\", 'question': 'How would you respond to the accusation that the United States is containing China while pushing for diplomatic talks?', 'annotator_id': '85', 'annotator1': None, 'annotator2': None, 'annotator3': None, 'inaudible': False, 'multiple_questions': False, 'affirmative_questions': False, 'index': 0, 'clarity_label': 'Clear Reply', 'evasion_label': 'Explicit'}\n",
      "\n",
      "Columns:\n",
      " ['title', 'date', 'president', 'url', 'question_order', 'interview_question', 'interview_answer', 'gpt3.5_summary', 'gpt3.5_prediction', 'question', 'annotator_id', 'annotator1', 'annotator2', 'annotator3', 'inaudible', 'multiple_questions', 'affirmative_questions', 'index', 'clarity_label', 'evasion_label']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTrain sample:\\n\", ds[\"train\"][0])\n",
    "print(\"\\nColumns:\\n\", ds[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86a8daf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"roberta-base\"\n",
    "MAX_LENGTH = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1d9f527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentencepiece in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (0.2.1)\n",
      "Requirement already satisfied: protobuf in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (6.33.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.3 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentencepiece protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b61f2045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification, \n",
    "    TrainingArguments, \n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21659d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (4.57.3)\n",
      "Requirement already satisfied: huggingface_hub in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (0.36.0)\n",
      "Collecting huggingface_hub\n",
      "  Using cached huggingface_hub-1.2.1-py3-none-any.whl (520 kB)\n",
      "Requirement already satisfied: accelerate in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (1.10.1)\n",
      "Requirement already satisfied: sentencepiece in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (0.2.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: requests in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: filelock in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from huggingface_hub) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from huggingface_hub) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from huggingface_hub) (2025.10.0)\n",
      "Requirement already satisfied: psutil in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from accelerate) (7.1.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from accelerate) (2.2.2)\n",
      "Requirement already satisfied: sympy in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: jinja2 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: networkx in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from torch>=2.0.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (2025.11.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from sympy->torch>=2.0.0->accelerate) (1.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.3 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade transformers huggingface_hub accelerate sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91e15a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Columns: ['title', 'date', 'president', 'url', 'question_order', 'interview_question', 'interview_answer', 'gpt3.5_summary', 'gpt3.5_prediction', 'question', 'annotator_id', 'annotator1', 'annotator2', 'annotator3', 'inaudible', 'multiple_questions', 'affirmative_questions', 'index', 'clarity_label', 'evasion_label']\n",
      "Sample Entry: {'title': \"The President's News Conference in Hanoi, Vietnam\", 'date': 'September 10, 2023', 'president': 'Joseph R. Biden', 'url': 'https://www.presidency.ucsb.edu/documents/the-presidents-news-conference-hanoi-vietnam-0', 'question_order': 1, 'interview_question': 'Q. Of the Biden administration. And accused the United States of containing China while pushing for diplomatic talks.How would you respond to that? And do you think President Xi is being sincere about getting the relationship back on track as he bans Apple in China?', 'interview_answer': \"Well, look, first of all, theI am sincere about getting the relationship right. And one of the things that is going on now is, China is beginning to change some of the rules of the game, in terms of trade and other issues.And so one of the things we talked about, for example, is that they're now talking about making sure that no Chineseno one in the Chinese Government can use a Western cell phone. Those kinds of things.And so, really, what this trip was aboutit was less about containing China. I don't want to contain China. I just want to make sure that we have a relationship with China that is on the up and up, squared away, everybody knows what it's all about. And one of the ways you do that is, you make sure that we are talking about the same things.And I think that one of the things we've doneI've tried to do, and I've talked with a number of my staff about this for the last, I guess, 6 monthsis, we have an opportunity to strengthen alliances around the world to maintain stability.That's what this trip was all about: having India cooperate much more with the United States, be closer with the United States, Vietnam being closer with the United States. It's not about containing China; it's about having a stable base, a stable base in the Indo-Pacific.And it'sfor example, when I was spending a lot of time talking with President Xi, he asked why we were doingwhy was I going to have the Quad, meaning Australia, India, Japan, and the United States? And I said, To maintain stability. It's not about isolating China. It's about making sure the rules of the roadeverything from airspace and space in the ocean isthe international rules of the road are abided by.And soand I hope thatI think that Prime Minister XiI mean, Xi has somesome difficulties right now. All countries end up with difficulties, and he had some economic difficulties he's working his way through. I want to see China succeed economically, but I want to see them succeed by the rules.The next question was to Bloomberg.\", 'gpt3.5_summary': 'The question consists of 2 parts: \\n1. How would you respond to the accusation that the United States is containing China while pushing for diplomatic talks?\\n2. Do you think President Xi is being sincere about getting the relationship back on track as he bans Apple in China?\\n\\nThe response provides the following information regarding these points:\\n1. The President expresses sincerity about getting the relationship between the United States and China right.\\n2. China is changing some of the rules of the game, such as banning Chinese government officials from using Western cell phones.\\n3. The purpose of the trip was not to contain China but to establish a stable relationship with China and strengthen alliances in the Indo-Pacific region.\\n4. The Quad (Australia, India, Japan, and United States) is not meant to isolate China but to maintain stability and ensure that international rules are followed.\\n5. President Xi has some economic difficulties, and the President hopes to see China succeed economically while also following the rules.', 'gpt3.5_prediction': \"Question part: 1. How would you respond to the accusation that the United States is containing China while pushing for diplomatic talks?\\nVerdict: 1.1 Explicit - The information requested is explicitly stated (in the requested form)\\nExplanation: The President directly responds to the accusation by stating that the purpose of the trip and their approach is not about containing China but about establishing a stable relationship and ensuring that both countries are on the same page.\\n\\nQuestion part: 2. Do you think President Xi is being sincere about getting the relationship back on track as he bans Apple in China?\\nVerdict: 1.1 Explicit - The information requested is explicitly stated (in the requested form)\\nExplanation: The President explicitly expresses their belief in President Xi's sincerity about getting the relationship back on track while also mentioning the difficulties China is facing and their hope that China follows the rules.\", 'question': 'How would you respond to the accusation that the United States is containing China while pushing for diplomatic talks?', 'annotator_id': '85', 'annotator1': None, 'annotator2': None, 'annotator3': None, 'inaudible': False, 'multiple_questions': False, 'affirmative_questions': False, 'index': 0, 'clarity_label': 'Clear Reply', 'evasion_label': 'Explicit'}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDataset Columns:\", ds['train'].column_names)\n",
    "print(\"Sample Entry:\", ds['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b684b10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_NORMALIZER = {\n",
    "    # Clear Reply mappings\n",
    "    'explicit': 'Explicit',\n",
    "    'clear reply': 'Explicit',\n",
    "    'clear': 'Explicit',\n",
    "    \n",
    "    # Ambivalent (Evasion) mappings\n",
    "    'implicit': 'Implicit',\n",
    "    'dodging': 'Dodging',\n",
    "    'general': 'General',\n",
    "    'deflection': 'Deflection',\n",
    "    'partial': 'Partial/half-answer',\n",
    "    'partial/half-answer': 'Partial/half-answer',\n",
    "    \n",
    "    # Clear Non-Reply mappings\n",
    "    'declining': 'Declining to answer',\n",
    "    'declining to answer': 'Declining to answer',\n",
    "    'ignorance': 'Claims ignorance',\n",
    "    'claims ignorance': 'Claims ignorance',\n",
    "    'clarification': 'Clarification',\n",
    "    \n",
    "    # Fallback mappings\n",
    "    'clear non-reply': 'Declining to answer',\n",
    "    'ambivalent': 'Implicit', # Default ambivalent to Implicit if unspecified\n",
    "    'ambiguous': 'Implicit'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6504df4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 3448 original rows...\n"
     ]
    }
   ],
   "source": [
    "raw_df = ds['train'].to_pandas()\n",
    "\n",
    "expanded_rows = []\n",
    "\n",
    "print(f\"Processing {len(raw_df)} original rows...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dfa31a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Size: 3448 (Exploded from 3448)\n",
      "Classes Found: ['Explicit' 'General' 'Partial/half-answer' 'Dodging' 'Implicit'\n",
      " 'Deflection' 'Declining to answer' 'Claims ignorance' 'Clarification']\n"
     ]
    }
   ],
   "source": [
    "for _, row in raw_df.iterrows():\n",
    "    q_text = row['interview_question']\n",
    "    a_text = row['interview_answer']\n",
    "    \n",
    "    # Collect all potential labels for this row\n",
    "    potential_labels = []\n",
    "    \n",
    "    # A. Check the 3 Annotators (Priority: High)\n",
    "    # The FAQ states any annotator is valid, so we train on ALL of them[cite: 210].\n",
    "    for col in ['annotator1', 'annotator2', 'annotator3']:\n",
    "        val = row.get(col)\n",
    "        if val and str(val).lower() not in ['nan', 'none', '']:\n",
    "            potential_labels.append(str(val).strip())\n",
    "            \n",
    "    # B. If no annotators (Training set usually), use evasion_label\n",
    "    if not potential_labels:\n",
    "        val = row.get('evasion_label')\n",
    "        if val and str(val).lower() not in ['nan', 'none', '']:\n",
    "            potential_labels.append(str(val).strip())\n",
    "\n",
    "    # C. Fallback: Use clarity_label if evasion is missing\n",
    "    # (e.g., \"Clear Reply\" -> \"Explicit\")\n",
    "    if not potential_labels:\n",
    "        clarity = row.get('clarity_label')\n",
    "        if clarity == 'Clear Reply':\n",
    "            potential_labels.append('Explicit')\n",
    "        elif clarity == 'Clear Non-Reply':\n",
    "            potential_labels.append('Declining to answer') # Generic fallback\n",
    "\n",
    "    # Add normalized rows to training data\n",
    "    for raw_label in potential_labels:\n",
    "        # Normalize (e.g., \"Partial\" -> \"Partial/half-answer\")\n",
    "        clean_label = LABEL_NORMALIZER.get(raw_label, raw_label)\n",
    "        \n",
    "        # Only add if it's one of our valid target classes\n",
    "        if clean_label in LABEL_NORMALIZER.values():\n",
    "            expanded_rows.append({\n",
    "                \"text\": q_text,\n",
    "                \"text_pair\": a_text,\n",
    "                \"label_str\": clean_label\n",
    "            })\n",
    "\n",
    "# Create final dataframe\n",
    "df_train = pd.DataFrame(expanded_rows)\n",
    "print(f\"Final Training Size: {len(df_train)} (Exploded from {len(raw_df)})\")\n",
    "print(f\"Classes Found: {df_train['label_str'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41a292da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights applied: tensor([3.2194, 4.1643, 2.6421, 1.0055, 0.5427, 0.3642, 0.9925, 0.7851, 4.8495])\n"
     ]
    }
   ],
   "source": [
    "unique_labels = sorted(df_train['label_str'].unique().tolist())\n",
    "label2id = {l: i for i, l in enumerate(unique_labels)}\n",
    "id2label = {i: l for i, l in enumerate(unique_labels)}\n",
    "\n",
    "df_train['labels'] = df_train['label_str'].map(label2id)\n",
    "\n",
    "# Compute Weights to handle imbalance (Explicit is ~30%, Clarification ~2%) [cite: 991]\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced', \n",
    "    classes=np.unique(df_train['labels']), \n",
    "    y=df_train['labels']\n",
    ")\n",
    "weights_tensor = torch.tensor(class_weights, dtype=torch.float)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "weights_tensor = weights_tensor.to(device)\n",
    "\n",
    "print(f\"Class Weights applied: {weights_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c7219db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3448/3448 [00:11<00:00, 296.28 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"], \n",
    "        examples[\"text_pair\"], \n",
    "        truncation=True, \n",
    "        max_length=MAX_LENGTH,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "hf_dataset = Dataset.from_pandas(df_train)\n",
    "hf_dataset = hf_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# Prepare for PyTorch\n",
    "cols = ['input_ids', 'attention_mask', 'labels']\n",
    "if 'token_type_ids' in hf_dataset.column_names: cols.append('token_type_ids')\n",
    "hf_dataset.set_format(type='torch', columns=cols)\n",
    "\n",
    "# 90/10 Train/Validation Split\n",
    "split_ds = hf_dataset.train_test_split(test_size=0.1, seed=42)\n",
    "test_dataset = split_ds['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22ac2b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        # Weighted Cross Entropy to help rare classes\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=weights_tensor)\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    # Metric is Macro F1 as per shared task guidelines [cite: 1068]\n",
    "    return {\"f1_macro\": f1_score(labels, predictions, average='macro')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfeeec7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy<2.0 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (1.26.4)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.3 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install \"numpy<2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c34d9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e65dca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/k8/vzhgxs_n55gb55djbh2q7wmr0000gn/T/ipykernel_63094/3815370037.py:22: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = WeightedTrainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='1940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  23/1940 26:21 < 40:06:09, 0.01 it/s, Epoch 0.06/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 32\u001b[0m\n\u001b[1;32m     22\u001b[0m trainer \u001b[38;5;241m=\u001b[39m WeightedTrainer(\n\u001b[1;32m     23\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     24\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     29\u001b[0m )\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mStarting Training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/trainer.py:2674\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2667\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2668\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2669\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2670\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2671\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2672\u001b[0m )\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2674\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2677\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2678\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2679\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2680\u001b[0m ):\n\u001b[1;32m   2681\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/trainer.py:4071\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   4068\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[1;32m   4069\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_wrt_gas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 4071\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/accelerate/accelerator.py:2734\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2733\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2734\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL,\n",
    "    num_labels=len(unique_labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ").to(device)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./clarity_final_model\",\n",
    "    learning_rate=2e-5,              # Recommended by paper [cite: 1162]\n",
    "    per_device_train_batch_size=8,   # Adjust to 4 if OOM\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,              # 5 epochs for convergence\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=split_ds[\"train\"],\n",
    "    eval_dataset=split_ds[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"\\nStarting Training...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05251fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- GENERATING PREDICTIONS ---\")\n",
    "\n",
    "# Run prediction loop on the Test Split\n",
    "predictions_output = trainer.predict(test_dataset)\n",
    "predicted_ids = np.argmax(predictions_output.predictions, axis=-1)\n",
    "\n",
    "# Convert IDs back to String Labels (Task 2 Output)\n",
    "predicted_labels = [id2label[pid] for pid in predicted_ids]\n",
    "\n",
    "# Apply Hierarchy Mapping for Task 1 (Figure 3 Logic)\n",
    "task1_clarity_preds = []\n",
    "for label in predicted_labels:\n",
    "    if label == 'Explicit':\n",
    "        task1_clarity_preds.append('Clear Reply')\n",
    "    elif label in ['Declining to answer', 'Claims ignorance', 'Clarification']:\n",
    "        task1_clarity_preds.append('Clear Non-Reply')\n",
    "    else:\n",
    "        # Implicit, Dodging, General, Deflection, Partial -> Ambivalent\n",
    "        task1_clarity_preds.append('Ambivalent Reply')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
