{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8536a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: datasets in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (4.4.1)\n",
      "Requirement already satisfied: httpx<1.0.0 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: fsspec[http]<=2025.10.0,>=2023.1.0 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (2025.10.0)\n",
      "Requirement already satisfied: packaging in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: xxhash in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: filelock in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (3.19.1)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from aiosignal>=1.4.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: anyio in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: idna in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: certifi in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.3 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c0bb1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saiesh/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/saiesh/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/saiesh/Library/Python/3.9/lib/python/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/saiesh/Library/Python/3.9/lib/python/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/saiesh/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/saiesh/Library/Python/3.9/lib/python/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/saiesh/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py\", line 519, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/saiesh/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py\", line 508, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/saiesh/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py\", line 400, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/saiesh/Library/Python/3.9/lib/python/site-packages/ipykernel/ipkernel.py\", line 368, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/saiesh/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/saiesh/Library/Python/3.9/lib/python/site-packages/ipykernel/ipkernel.py\", line 455, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/saiesh/Library/Python/3.9/lib/python/site-packages/ipykernel/zmqshell.py\", line 602, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/saiesh/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/saiesh/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/saiesh/Library/Python/3.9/lib/python/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/saiesh/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/saiesh/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/saiesh/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/k8/vzhgxs_n55gb55djbh2q7wmr0000gn/T/ipykernel_55433/3618178443.py\", line 2, in <module>\n",
      "    from datasets import load_dataset\n",
      "  File \"/Users/saiesh/Library/Python/3.9/lib/python/site-packages/datasets/__init__.py\", line 17, in <module>\n",
      "    from .arrow_dataset import Column, Dataset\n",
      "  File \"/Users/saiesh/Library/Python/3.9/lib/python/site-packages/datasets/arrow_dataset.py\", line 104, in <module>\n",
      "    from .formatting import format_table, get_format_type_from_alias, get_formatter, query_table\n",
      "  File \"/Users/saiesh/Library/Python/3.9/lib/python/site-packages/datasets/formatting/__init__.py\", line 91, in <module>\n",
      "    from .torch_formatter import TorchFormatter\n",
      "  File \"/Users/saiesh/Library/Python/3.9/lib/python/site-packages/datasets/formatting/torch_formatter.py\", line 32, in <module>\n",
      "    import torch\n",
      "  File \"/Users/saiesh/Library/Python/3.9/lib/python/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/saiesh/Library/Python/3.9/lib/python/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/saiesh/Library/Python/3.9/lib/python/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/saiesh/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/saiesh/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/saiesh/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "# importing the dataset directly from huggingface\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "ds = load_dataset(\"ailsntua/QEvasion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1b3e2ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'date', 'president', 'url', 'question_order', 'interview_question', 'interview_answer', 'gpt3.5_summary', 'gpt3.5_prediction', 'question', 'annotator_id', 'annotator1', 'annotator2', 'annotator3', 'inaudible', 'multiple_questions', 'affirmative_questions', 'index', 'clarity_label', 'evasion_label'],\n",
       "        num_rows: 3448\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['title', 'date', 'president', 'url', 'question_order', 'interview_question', 'interview_answer', 'gpt3.5_summary', 'gpt3.5_prediction', 'question', 'annotator_id', 'annotator1', 'annotator2', 'annotator3', 'inaudible', 'multiple_questions', 'affirmative_questions', 'index', 'clarity_label', 'evasion_label'],\n",
       "        num_rows: 308\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d143540b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train sample:\n",
      " {'title': \"The President's News Conference in Hanoi, Vietnam\", 'date': 'September 10, 2023', 'president': 'Joseph R. Biden', 'url': 'https://www.presidency.ucsb.edu/documents/the-presidents-news-conference-hanoi-vietnam-0', 'question_order': 1, 'interview_question': 'Q. Of the Biden administration. And accused the United States of containing China while pushing for diplomatic talks.How would you respond to that? And do you think President Xi is being sincere about getting the relationship back on track as he bans Apple in China?', 'interview_answer': \"Well, look, first of all, theI am sincere about getting the relationship right. And one of the things that is going on now is, China is beginning to change some of the rules of the game, in terms of trade and other issues.And so one of the things we talked about, for example, is that they're now talking about making sure that no Chineseno one in the Chinese Government can use a Western cell phone. Those kinds of things.And so, really, what this trip was aboutit was less about containing China. I don't want to contain China. I just want to make sure that we have a relationship with China that is on the up and up, squared away, everybody knows what it's all about. And one of the ways you do that is, you make sure that we are talking about the same things.And I think that one of the things we've doneI've tried to do, and I've talked with a number of my staff about this for the last, I guess, 6 monthsis, we have an opportunity to strengthen alliances around the world to maintain stability.That's what this trip was all about: having India cooperate much more with the United States, be closer with the United States, Vietnam being closer with the United States. It's not about containing China; it's about having a stable base, a stable base in the Indo-Pacific.And it'sfor example, when I was spending a lot of time talking with President Xi, he asked why we were doingwhy was I going to have the Quad, meaning Australia, India, Japan, and the United States? And I said, To maintain stability. It's not about isolating China. It's about making sure the rules of the roadeverything from airspace and space in the ocean isthe international rules of the road are abided by.And soand I hope thatI think that Prime Minister XiI mean, Xi has somesome difficulties right now. All countries end up with difficulties, and he had some economic difficulties he's working his way through. I want to see China succeed economically, but I want to see them succeed by the rules.The next question was to Bloomberg.\", 'gpt3.5_summary': 'The question consists of 2 parts: \\n1. How would you respond to the accusation that the United States is containing China while pushing for diplomatic talks?\\n2. Do you think President Xi is being sincere about getting the relationship back on track as he bans Apple in China?\\n\\nThe response provides the following information regarding these points:\\n1. The President expresses sincerity about getting the relationship between the United States and China right.\\n2. China is changing some of the rules of the game, such as banning Chinese government officials from using Western cell phones.\\n3. The purpose of the trip was not to contain China but to establish a stable relationship with China and strengthen alliances in the Indo-Pacific region.\\n4. The Quad (Australia, India, Japan, and United States) is not meant to isolate China but to maintain stability and ensure that international rules are followed.\\n5. President Xi has some economic difficulties, and the President hopes to see China succeed economically while also following the rules.', 'gpt3.5_prediction': \"Question part: 1. How would you respond to the accusation that the United States is containing China while pushing for diplomatic talks?\\nVerdict: 1.1 Explicit - The information requested is explicitly stated (in the requested form)\\nExplanation: The President directly responds to the accusation by stating that the purpose of the trip and their approach is not about containing China but about establishing a stable relationship and ensuring that both countries are on the same page.\\n\\nQuestion part: 2. Do you think President Xi is being sincere about getting the relationship back on track as he bans Apple in China?\\nVerdict: 1.1 Explicit - The information requested is explicitly stated (in the requested form)\\nExplanation: The President explicitly expresses their belief in President Xi's sincerity about getting the relationship back on track while also mentioning the difficulties China is facing and their hope that China follows the rules.\", 'question': 'How would you respond to the accusation that the United States is containing China while pushing for diplomatic talks?', 'annotator_id': '85', 'annotator1': None, 'annotator2': None, 'annotator3': None, 'inaudible': False, 'multiple_questions': False, 'affirmative_questions': False, 'index': 0, 'clarity_label': 'Clear Reply', 'evasion_label': 'Explicit'}\n",
      "\n",
      "Columns:\n",
      " ['title', 'date', 'president', 'url', 'question_order', 'interview_question', 'interview_answer', 'gpt3.5_summary', 'gpt3.5_prediction', 'question', 'annotator_id', 'annotator1', 'annotator2', 'annotator3', 'inaudible', 'multiple_questions', 'affirmative_questions', 'index', 'clarity_label', 'evasion_label']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTrain sample:\\n\", ds[\"train\"][0])\n",
    "print(\"\\nColumns:\\n\", ds[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86a8daf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"microsoft/deberta-v3-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1d9f527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentencepiece in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (0.2.1)\n",
      "Requirement already satisfied: protobuf in /Users/saiesh/Library/Python/3.9/lib/python/site-packages (6.33.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.3 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentencepiece protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b61f2045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification, \n",
    "    TrainingArguments, \n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91e15a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Columns: ['title', 'date', 'president', 'url', 'question_order', 'interview_question', 'interview_answer', 'gpt3.5_summary', 'gpt3.5_prediction', 'question', 'annotator_id', 'annotator1', 'annotator2', 'annotator3', 'inaudible', 'multiple_questions', 'affirmative_questions', 'index', 'clarity_label', 'evasion_label']\n",
      "Sample Entry: {'title': \"The President's News Conference in Hanoi, Vietnam\", 'date': 'September 10, 2023', 'president': 'Joseph R. Biden', 'url': 'https://www.presidency.ucsb.edu/documents/the-presidents-news-conference-hanoi-vietnam-0', 'question_order': 1, 'interview_question': 'Q. Of the Biden administration. And accused the United States of containing China while pushing for diplomatic talks.How would you respond to that? And do you think President Xi is being sincere about getting the relationship back on track as he bans Apple in China?', 'interview_answer': \"Well, look, first of all, theI am sincere about getting the relationship right. And one of the things that is going on now is, China is beginning to change some of the rules of the game, in terms of trade and other issues.And so one of the things we talked about, for example, is that they're now talking about making sure that no Chineseno one in the Chinese Government can use a Western cell phone. Those kinds of things.And so, really, what this trip was aboutit was less about containing China. I don't want to contain China. I just want to make sure that we have a relationship with China that is on the up and up, squared away, everybody knows what it's all about. And one of the ways you do that is, you make sure that we are talking about the same things.And I think that one of the things we've doneI've tried to do, and I've talked with a number of my staff about this for the last, I guess, 6 monthsis, we have an opportunity to strengthen alliances around the world to maintain stability.That's what this trip was all about: having India cooperate much more with the United States, be closer with the United States, Vietnam being closer with the United States. It's not about containing China; it's about having a stable base, a stable base in the Indo-Pacific.And it'sfor example, when I was spending a lot of time talking with President Xi, he asked why we were doingwhy was I going to have the Quad, meaning Australia, India, Japan, and the United States? And I said, To maintain stability. It's not about isolating China. It's about making sure the rules of the roadeverything from airspace and space in the ocean isthe international rules of the road are abided by.And soand I hope thatI think that Prime Minister XiI mean, Xi has somesome difficulties right now. All countries end up with difficulties, and he had some economic difficulties he's working his way through. I want to see China succeed economically, but I want to see them succeed by the rules.The next question was to Bloomberg.\", 'gpt3.5_summary': 'The question consists of 2 parts: \\n1. How would you respond to the accusation that the United States is containing China while pushing for diplomatic talks?\\n2. Do you think President Xi is being sincere about getting the relationship back on track as he bans Apple in China?\\n\\nThe response provides the following information regarding these points:\\n1. The President expresses sincerity about getting the relationship between the United States and China right.\\n2. China is changing some of the rules of the game, such as banning Chinese government officials from using Western cell phones.\\n3. The purpose of the trip was not to contain China but to establish a stable relationship with China and strengthen alliances in the Indo-Pacific region.\\n4. The Quad (Australia, India, Japan, and United States) is not meant to isolate China but to maintain stability and ensure that international rules are followed.\\n5. President Xi has some economic difficulties, and the President hopes to see China succeed economically while also following the rules.', 'gpt3.5_prediction': \"Question part: 1. How would you respond to the accusation that the United States is containing China while pushing for diplomatic talks?\\nVerdict: 1.1 Explicit - The information requested is explicitly stated (in the requested form)\\nExplanation: The President directly responds to the accusation by stating that the purpose of the trip and their approach is not about containing China but about establishing a stable relationship and ensuring that both countries are on the same page.\\n\\nQuestion part: 2. Do you think President Xi is being sincere about getting the relationship back on track as he bans Apple in China?\\nVerdict: 1.1 Explicit - The information requested is explicitly stated (in the requested form)\\nExplanation: The President explicitly expresses their belief in President Xi's sincerity about getting the relationship back on track while also mentioning the difficulties China is facing and their hope that China follows the rules.\", 'question': 'How would you respond to the accusation that the United States is containing China while pushing for diplomatic talks?', 'annotator_id': '85', 'annotator1': None, 'annotator2': None, 'annotator3': None, 'inaudible': False, 'multiple_questions': False, 'affirmative_questions': False, 'index': 0, 'clarity_label': 'Clear Reply', 'evasion_label': 'Explicit'}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDataset Columns:\", ds['train'].column_names)\n",
    "print(\"Sample Entry:\", ds['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b684b10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_NORMALIZER = {\n",
    "    # Clear Reply mappings\n",
    "    'explicit': 'Explicit',\n",
    "    'clear reply': 'Explicit',\n",
    "    'clear': 'Explicit',\n",
    "    \n",
    "    # Ambivalent (Evasion) mappings\n",
    "    'implicit': 'Implicit',\n",
    "    'dodging': 'Dodging',\n",
    "    'general': 'General',\n",
    "    'deflection': 'Deflection',\n",
    "    'partial': 'Partial/half-answer',\n",
    "    'partial/half-answer': 'Partial/half-answer',\n",
    "    \n",
    "    # Clear Non-Reply mappings\n",
    "    'declining': 'Declining to answer',\n",
    "    'declining to answer': 'Declining to answer',\n",
    "    'ignorance': 'Claims ignorance',\n",
    "    'claims ignorance': 'Claims ignorance',\n",
    "    'clarification': 'Clarification',\n",
    "    \n",
    "    # Fallback mappings\n",
    "    'clear non-reply': 'Declining to answer',\n",
    "    'ambivalent': 'Implicit', # Default ambivalent to Implicit if unspecified\n",
    "    'ambiguous': 'Implicit'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6504df4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 3448 original rows...\n"
     ]
    }
   ],
   "source": [
    "raw_df = ds['train'].to_pandas()\n",
    "\n",
    "expanded_rows = []\n",
    "\n",
    "print(f\"Processing {len(raw_df)} original rows...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dfa31a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Size: 3448 (Exploded from 3448)\n",
      "Classes Found: ['Explicit' 'General' 'Partial/half-answer' 'Dodging' 'Implicit'\n",
      " 'Deflection' 'Declining to answer' 'Claims ignorance' 'Clarification']\n"
     ]
    }
   ],
   "source": [
    "for _, row in raw_df.iterrows():\n",
    "    q_text = row['interview_question']\n",
    "    a_text = row['interview_answer']\n",
    "    \n",
    "    # Collect all potential labels for this row\n",
    "    potential_labels = []\n",
    "    \n",
    "    # A. Check the 3 Annotators (Priority: High)\n",
    "    # The FAQ states any annotator is valid, so we train on ALL of them[cite: 210].\n",
    "    for col in ['annotator1', 'annotator2', 'annotator3']:\n",
    "        val = row.get(col)\n",
    "        if val and str(val).lower() not in ['nan', 'none', '']:\n",
    "            potential_labels.append(str(val).strip())\n",
    "            \n",
    "    # B. If no annotators (Training set usually), use evasion_label\n",
    "    if not potential_labels:\n",
    "        val = row.get('evasion_label')\n",
    "        if val and str(val).lower() not in ['nan', 'none', '']:\n",
    "            potential_labels.append(str(val).strip())\n",
    "\n",
    "    # C. Fallback: Use clarity_label if evasion is missing\n",
    "    # (e.g., \"Clear Reply\" -> \"Explicit\")\n",
    "    if not potential_labels:\n",
    "        clarity = row.get('clarity_label')\n",
    "        if clarity == 'Clear Reply':\n",
    "            potential_labels.append('Explicit')\n",
    "        elif clarity == 'Clear Non-Reply':\n",
    "            potential_labels.append('Declining to answer') # Generic fallback\n",
    "\n",
    "    # Add normalized rows to training data\n",
    "    for raw_label in potential_labels:\n",
    "        # Normalize (e.g., \"Partial\" -> \"Partial/half-answer\")\n",
    "        clean_label = LABEL_NORMALIZER.get(raw_label, raw_label)\n",
    "        \n",
    "        # Only add if it's one of our valid target classes\n",
    "        if clean_label in LABEL_NORMALIZER.values():\n",
    "            expanded_rows.append({\n",
    "                \"text\": q_text,\n",
    "                \"text_pair\": a_text,\n",
    "                \"label_str\": clean_label\n",
    "            })\n",
    "\n",
    "# Create final dataframe\n",
    "df_train = pd.DataFrame(expanded_rows)\n",
    "print(f\"Final Training Size: {len(df_train)} (Exploded from {len(raw_df)})\")\n",
    "print(f\"Classes Found: {df_train['label_str'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41a292da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights applied: tensor([3.2194, 4.1643, 2.6421, 1.0055, 0.5427, 0.3642, 0.9925, 0.7851, 4.8495])\n"
     ]
    }
   ],
   "source": [
    "unique_labels = sorted(df_train['label_str'].unique().tolist())\n",
    "label2id = {l: i for i, l in enumerate(unique_labels)}\n",
    "id2label = {i: l for i, l in enumerate(unique_labels)}\n",
    "\n",
    "df_train['labels'] = df_train['label_str'].map(label2id)\n",
    "\n",
    "# Compute Weights to handle imbalance (Explicit is ~30%, Clarification ~2%) [cite: 991]\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced', \n",
    "    classes=np.unique(df_train['labels']), \n",
    "    y=df_train['labels']\n",
    ")\n",
    "weights_tensor = torch.tensor(class_weights, dtype=torch.float)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "weights_tensor = weights_tensor.to(device)\n",
    "\n",
    "print(f\"Class Weights applied: {weights_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c7219db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saiesh/Library/Python/3.9/lib/python/site-packages/transformers/convert_slow_tokenizer.py:566: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 12\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpreprocess_function\u001b[39m(examples):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer(\n\u001b[1;32m      5\u001b[0m         examples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[1;32m      6\u001b[0m         examples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_pair\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m         padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m     )\n\u001b[0;32m---> 12\u001b[0m hf_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pandas(df_train)\n\u001b[1;32m     13\u001b[0m hf_dataset \u001b[38;5;241m=\u001b[39m hf_dataset\u001b[38;5;241m.\u001b[39mmap(preprocess_function, batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Prepare for PyTorch\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"], \n",
    "        examples[\"text_pair\"], \n",
    "        truncation=True, \n",
    "        max_length=MAX_LENGTH,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "hf_dataset = Dataset.from_pandas(df_train)\n",
    "hf_dataset = hf_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# Prepare for PyTorch\n",
    "cols = ['input_ids', 'attention_mask', 'labels']\n",
    "if 'token_type_ids' in hf_dataset.column_names: cols.append('token_type_ids')\n",
    "hf_dataset.set_format(type='torch', columns=cols)\n",
    "\n",
    "# 90/10 Train/Validation Split\n",
    "split_ds = hf_dataset.train_test_split(test_size=0.1, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ac2b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        # Weighted Cross Entropy to help rare classes\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=weights_tensor)\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    # Metric is Macro F1 as per shared task guidelines [cite: 1068]\n",
    "    return {\"f1_macro\": f1_score(labels, predictions, average='macro')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e65dca9",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Can't load the model for 'microsoft/deberta-v3-base'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'microsoft/deberta-v3-base' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/modeling_utils.py:1108\u001b[0m, in \u001b[0;36m_get_resolved_checkpoint_files\u001b[0;34m(pretrained_model_name_or_path, subfolder, variant, gguf_file, from_tf, from_flax, use_safetensors, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash, is_remote_code, transformers_explicit_filename)\u001b[0m\n\u001b[1;32m   1096\u001b[0m cached_file_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1097\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m: cache_dir,\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforce_download\u001b[39m\u001b[38;5;124m\"\u001b[39m: force_download,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1105\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhas_file_kwargs,\n\u001b[1;32m   1106\u001b[0m }\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m-> 1108\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mhas_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_weights_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhas_file_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_remote_code\n\u001b[1;32m   1110\u001b[0m ):\n\u001b[1;32m   1111\u001b[0m     Thread(\n\u001b[1;32m   1112\u001b[0m         target\u001b[38;5;241m=\u001b[39mauto_conversion,\n\u001b[1;32m   1113\u001b[0m         args\u001b[38;5;241m=\u001b[39m(pretrained_model_name_or_path,),\n\u001b[1;32m   1114\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore_errors_during_conversion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcached_file_kwargs},\n\u001b[1;32m   1115\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThread-auto_conversion\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1116\u001b[0m     )\u001b[38;5;241m.\u001b[39mstart()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/utils/hub.py:680\u001b[0m, in \u001b[0;36mhas_file\u001b[0;34m(path_or_repo, filename, revision, proxies, token, local_files_only, cache_dir, repo_type, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 680\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mget_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_hub_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuild_hf_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhttp_user_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mSSLError, requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mProxyError):\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;66;03m# Actually raise for those subclasses of ConnectionError\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: head() got an unexpected keyword argument 'allow_redirects'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForSequenceClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mMODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43munique_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mid2label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mid2label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel2id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel2id\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m      9\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./clarity_final_model\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2e-5\u001b[39m,              \u001b[38;5;66;03m# Recommended by paper [cite: 1162]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     report_to\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     22\u001b[0m trainer \u001b[38;5;241m=\u001b[39m WeightedTrainer(\n\u001b[1;32m     23\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     24\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     29\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/models/auto/auto_factory.py:604\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    602\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mconfig_class \u001b[38;5;241m==\u001b[39m config\u001b[38;5;241m.\u001b[39msub_configs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    603\u001b[0m         config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget_text_config()\n\u001b[0;32m--> 604\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    609\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    610\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/modeling_utils.py:277\u001b[0m, in \u001b[0;36mrestore_default_dtype.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/modeling_utils.py:4900\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4890\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4891\u001b[0m     gguf_file\n\u001b[1;32m   4892\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4893\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m ((\u001b[38;5;28misinstance\u001b[39m(device_map, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map)\n\u001b[1;32m   4894\u001b[0m ):\n\u001b[1;32m   4895\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   4896\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOne or more modules is configured to be mapped to disk. Disk offload is not supported for models \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4897\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloaded from GGUF files.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4898\u001b[0m     )\n\u001b[0;32m-> 4900\u001b[0m checkpoint_files, sharded_metadata \u001b[38;5;241m=\u001b[39m \u001b[43m_get_resolved_checkpoint_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4901\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4902\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4903\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvariant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4904\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgguf_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgguf_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4905\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4906\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4907\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4908\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4909\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4910\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4911\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4912\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4913\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4914\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_auto_class\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   4917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransformers_explicit_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformers_explicit_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4920\u001b[0m is_sharded \u001b[38;5;241m=\u001b[39m sharded_metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4921\u001b[0m is_quantized \u001b[38;5;241m=\u001b[39m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/modeling_utils.py:1160\u001b[0m, in \u001b[0;36m_get_resolved_checkpoint_files\u001b[0;34m(pretrained_model_name_or_path, subfolder, variant, gguf_file, from_tf, from_flax, use_safetensors, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash, is_remote_code, transformers_explicit_filename)\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1159\u001b[0m         \u001b[38;5;66;03m# For any other exception, we throw a generic error.\u001b[39;00m\n\u001b[0;32m-> 1160\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m   1161\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load the model for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. If you were trying to load it\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1162\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m from \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, make sure you don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have a local directory with the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1163\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m same name. Otherwise, make sure \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is the correct path to a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1164\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m directory containing a file named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_add_variant(WEIGHTS_NAME,\u001b[38;5;250m \u001b[39mvariant)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1165\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTF2_WEIGHTS_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTF_WEIGHTS_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFLAX_WEIGHTS_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1166\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_local:\n\u001b[1;32m   1169\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading weights file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marchive_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Can't load the model for 'microsoft/deberta-v3-base'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'microsoft/deberta-v3-base' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack."
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL,\n",
    "    num_labels=len(unique_labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ").to(device)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./clarity_final_model\",\n",
    "    learning_rate=2e-5,              # Recommended by paper [cite: 1162]\n",
    "    per_device_train_batch_size=8,   # Adjust to 4 if OOM\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,              # 5 epochs for convergence\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=split_ds[\"train\"],\n",
    "    eval_dataset=split_ds[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"\\nStarting Training...\")\n",
    "trainer.train()\n",
    "\n",
    "trainer.save_model(\"./final_clarity_submission_model\")\n",
    "tokenizer.save_pretrained(\"./final_clarity_submission_model\")\n",
    "print(\"Training Complete. Model saved to ./final_clarity_submission_model\")\n",
    "\n",
    "trainer.save_model(\"./final_clarity_submission_model\")\n",
    "tokenizer.save_pretrained(\"./final_clarity_submission_model\")\n",
    "print(\"Training Complete. Model saved to ./final_clarity_submission_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05251fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_prediction(pred_label):\n",
    "    # Task 2 Output (Evasion Level) is just the label itself\n",
    "    task2_output = pred_label\n",
    "    \n",
    "    # Task 1 Output (Clarity Level) - Based on Figure 3 Hierarchy\n",
    "    if pred_label == 'Explicit':\n",
    "        task1_output = 'Clear Reply'\n",
    "        \n",
    "    elif pred_label in ['Implicit', 'Dodging', 'General', 'Deflection', 'Partial/half-answer']:\n",
    "        task1_output = 'Ambivalent Reply'\n",
    "        \n",
    "    elif pred_label in ['Declining to answer', 'Claims ignorance', 'Clarification']:\n",
    "        task1_output = 'Clear Non-Reply'\n",
    "        \n",
    "    else:\n",
    "        # Fallback (Should not happen if trained correctly)\n",
    "        task1_output = 'Ambivalent Reply'\n",
    "        \n",
    "    return task1_output, task2_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
